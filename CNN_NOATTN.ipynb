{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X533N859P5hW"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pickle as pkl\n",
    "import html\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, pandas as pd\n",
    "from sacrebleu import raw_corpus_bleu, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HD48r0m6P5he"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgtkZTv-P5jT"
   },
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYfXvIBXT3Ju"
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_IDX = 2\n",
    "UNK_IDX = 3\n",
    "VOCAB_SIZE = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBs90LXDU1eS"
   },
   "outputs": [],
   "source": [
    "def pkl_loader(file_name):\n",
    "    with open(file_name+'.p', 'rb') as f:\n",
    "        objct = pkl.load(f)\n",
    "    return(objct)\n",
    "\n",
    "def pkl_dumper(obj, file_name):\n",
    "    with open(file_name+'.p', 'wb') as f:\n",
    "        pkl.dump(obj, f, protocol=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_wordvec(lan):\n",
    "    if lan == 'zh':\n",
    "        filename = 'wiki.zh.vec' #Chinese\n",
    "    elif lan == 'en':\n",
    "        filename = 'wiki-news-300d-1M.vec' #English\n",
    "    else:\n",
    "        filename = 'wiki.vi.vec' #Vietnamese\n",
    "    with open(os.path.join(data_dir, filename),encoding='utf-8') as f:\n",
    "        word_vecs = np.zeros((VOCAB_SIZE+4, 300))\n",
    "        word_vecs[UNK_IDX] = np.random.normal(scale=0.6, size=(300, ))\n",
    "        word_vecs[SOS_token] = np.random.normal(scale=0.6, size=(300, ))\n",
    "        word_vecs[EOS_token] = np.random.normal(scale=0.6, size=(300, ))\n",
    "\n",
    "        words_ft = {'<pad>': PAD_IDX,\n",
    "                   '<unk>': UNK_IDX, \n",
    "                   '<sos>': SOS_token,\n",
    "                   '<eos>': EOS_token}\n",
    "        idx2words_ft = {PAD_IDX:'<pad>', UNK_IDX: '<unk>', SOS_token: '<sos>', EOS_token: '<eos>'}\n",
    "        ordered_words_ft = ['<sos>', '<eos>', '<pad>', '<unk>']\n",
    "        count = 0\n",
    "        for i, line in enumerate(f):\n",
    "            if len(idx2words_ft) >= VOCAB_SIZE+4: \n",
    "                break\n",
    "            s = line.split()\n",
    "            if (np.asarray(s[1:]).size == 300):\n",
    "                word_vecs[count+4, :] = np.asarray(s[1:])\n",
    "                words_ft[s[0]] = count+4\n",
    "                idx2words_ft[count+4] = s[0]\n",
    "                count += 1\n",
    "    word_vecs = torch.FloatTensor(word_vecs)\n",
    "    pkl_dumper(word_vecs, os.path.join(data_dir, lan + '_word_vecs'))\n",
    "    pkl_dumper(words_ft, os.path.join(data_dir, lan + '_words_ft'))\n",
    "    pkl_dumper(idx2words_ft, os.path.join(data_dir, lan + '_idx2words_ft'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_pretrained_wordvec('zh')\n",
    "# load_pretrained_wordvec('en')\n",
    "# load_pretrained_wordvec('vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1Hs2NidTylC"
   },
   "outputs": [],
   "source": [
    "#load pretrained vectors\n",
    "word_vecs = {}\n",
    "word2index = {}\n",
    "index2word = {}\n",
    "\n",
    "word_vecs['en'] = pkl_loader(data_dir+'/en_word_vecs')\n",
    "word_vecs['zh'] = pkl_loader(data_dir+'/zh_word_vecs')\n",
    "word_vecs['vi'] = pkl_loader(data_dir+'/vi_word_vecs')\n",
    "word2index['en'] = pkl_loader(data_dir+'/en_words_ft')\n",
    "word2index['zh'] = pkl_loader(data_dir+'/zh_words_ft')\n",
    "word2index['vi'] = pkl_loader(data_dir+'/vi_words_ft')\n",
    "index2word['en'] = pkl_loader(data_dir+'/en_idx2words_ft')\n",
    "index2word['zh'] = pkl_loader(data_dir+'/zh_idx2words_ft')\n",
    "index2word['vi'] = pkl_loader(data_dir+'/vi_idx2words_ft')\n",
    "\n",
    "VOCAB_SIZE = len(word2index['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPxh8_FbUGRp"
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name, index2word, word2index):\n",
    "        self.name = name\n",
    "        self.word2index = word2index\n",
    "        self.index2word = index2word\n",
    "        self.n_words = len(index2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8LdK97ZP5jY"
   },
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = html.unescape(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0sHz30YP5jh"
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFEWmec6P5jl"
   },
   "outputs": [],
   "source": [
    "def loadingLangs(sourcelang, targetlang, setname):\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    print('Reading lines...')\n",
    "    # Read the file \n",
    "    with open(data_dir+'/iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,sourcelang), encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            input_ls.append([normalizeString(word) for word in line.split()])\n",
    "    with open(data_dir+'/iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,targetlang), encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            output_ls.append([normalizeString(word) for word in line.split()])\n",
    "    pairs = list(zip(input_ls, output_ls))\n",
    "    pairs = [pair for pair in pairs if (len(pair[0])>0 and len(pair[1])>0)]\n",
    "    print('Read %s sentence pairs'%(len(input_ls)))\n",
    "    if sourcelang == 'zh':\n",
    "        input_lang = Lang(sourcelang, index2word['zh'], word2index['zh'])\n",
    "    else:\n",
    "        input_lang = Lang(sourcelang, index2word['vi'], word2index['vi']) ####\n",
    "    output_lang = Lang(targetlang, index2word['en'], word2index['en'])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213377 sentence pairs\n",
      "Counted words:\n",
      "zh 50004\n",
      "en 50004\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Counted words:\n",
      "zh 50004\n",
      "en 50004\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Counted words:\n",
      "zh 50004\n",
      "en 50004\n"
     ]
    }
   ],
   "source": [
    "source_tra, target_tra, pairs_tra = loadingLangs('zh', 'en', 'train')\n",
    "source_val, target_val, pairs_val = loadingLangs('zh', 'en', 'dev')\n",
    "source_tes, target_tes, pairs_tes = loadingLangs('zh', 'en', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2-qa2MvP5j5"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzKhEtT3P5kH"
   },
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 38\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTXvnrMWP5kS"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair,source,target):\n",
    "    input_lang = source\n",
    "    output_lang = target\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]).reshape((-1))\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1]).reshape((-1))\n",
    "    return (input_tensor, input_tensor.shape[0], target_tensor, target_tensor.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXLSdH-UP5kZ"
   },
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, source, target, pairs):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        inp_ten, inp_len, tar_ten, tar_len = tensorsFromPair(self.pairs[key], self.source, self.target)\n",
    "        item = {}\n",
    "        item['inputtensor'] = inp_ten[:MAX_SENT_LEN]\n",
    "        item['inputlen'] = min(inp_len, MAX_SENT_LEN)\n",
    "        item['targettensor'] = tar_ten[:MAX_SENT_LEN]\n",
    "        item['targetlen'] = min(tar_len, MAX_SENT_LEN)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7Iw5viDP5ki"
   },
   "outputs": [],
   "source": [
    "train_data = NMTDataset(source_tra, target_tra, pairs_tra)\n",
    "val_data = NMTDataset(source_tra, target_tra, pairs_val)\n",
    "test_data = NMTDataset(source_tra, target_tra, pairs_tes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Qrj4xY-P5kv"
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBPM1pRNP5kv"
   },
   "outputs": [],
   "source": [
    "#collate function\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    src_data, tar_data, src_len, tar_len = [], [], [], []\n",
    "    \n",
    "    for datum in batch: \n",
    "        src_len.append(datum['inputlen'])\n",
    "        tar_len.append(datum['targetlen'])\n",
    "    \n",
    "    max_length = [np.max(src_len), np.max(tar_len)]\n",
    "    for datum in batch: \n",
    "        \n",
    "        src_datum = np.pad(np.array(datum['inputtensor']),\n",
    "                                pad_width=((0, max_length[0]-datum['inputlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        tar_datum = np.pad(np.array(datum['targettensor']),\n",
    "                                pad_width=((0, max_length[1]-datum['targetlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_datum)\n",
    "        tar_data.append(tar_datum)\n",
    "        \n",
    "        \n",
    "    ind_dec_order = np.argsort(src_len)[::-1]\n",
    "    src_data = np.array(src_data)[ind_dec_order]\n",
    "    src_len = np.array(src_len)[ind_dec_order]\n",
    "    tar_data = np.array(tar_data)[ind_dec_order]\n",
    "    tar_len = np.array(tar_len)[ind_dec_order]\n",
    "    return [torch.from_numpy(np.array(src_data)).to(device),torch.from_numpy(np.array(tar_data)).to(device),\n",
    "                torch.LongTensor(np.array(src_len)).to(device),torch.LongTensor(np.array(tar_len)).to(device)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UHPDKS4P5k3"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_func)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=False, collate_fn=collate_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WO ATTN\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, emb_size=300, pretrained=False, ker_size=3, dropout_p=0.1):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_size = emb_size\n",
    "        if pretrained==True:\n",
    "            word_vec = word_vecs[source_tra.name]\n",
    "            self.embedding = nn.Embedding(input_size, emb_size, padding_idx=PAD_IDX)\n",
    "            self.embedding.weight = nn.Parameter(word_vec)\n",
    "            self.embedding.requires_grad = False\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(input_size, emb_size, padding_idx=PAD_IDX)\n",
    "          \n",
    "          \n",
    "        self.seq1 = nn.Sequential(nn.Conv1d(emb_size, hidden_size, kernel_size=ker_size, padding=(ker_size-1)//2),\n",
    "                                nn.ReLU())\n",
    "        self.seq2 = nn.Sequential(nn.Conv1d(hidden_size, hidden_size, kernel_size=ker_size, padding=(ker_size-1)//2),\n",
    "                                nn.ReLU())\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        seq_len, batch_size = input.size()\n",
    "        # input size for conv1d is , N is a batch size, C denotes a number of channels, L is a length of signal sequence.\n",
    "        output = self.embedding(input) ## SL*BS*ES\n",
    "        output = output.permute(1, 2, 0) \n",
    "        output = self.seq1(output)\n",
    "        output = self.seq2(output)\n",
    "        hidden = torch.sum(output, dim=2)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "\n",
    "        output = output.permute(2, 0, 1)\n",
    "        hidden = self.fc(hidden)\n",
    "        hidden = F.relu(self.dropout(hidden))\n",
    "        hidden = self.fc(hidden)\n",
    "        #print(hidden.size(), output.size()) #output: 1*BS*HS; hidden: SL*BS*HS\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wprKLpELP5lW"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx = PAD_IDX)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.view(1,-1)\n",
    "        batch_size = input.size()[1]\n",
    "        #print('in Decoder, batch_size is {}'.format(batch_size))\n",
    "        \n",
    "        #print('in Decoder, input before embedded layer is {}, dimension is {}'.format(input,input.size()))\n",
    "        output = self.embedding(input).view(1, batch_size, -1)\n",
    "        #print('in Decoder, output after embedded is {}, dimension is {} \\n'.format(output, output.size()))\n",
    "        output = F.relu(output)\n",
    "        #print('in Decoder, output after relu is {}, dimension is {} \\n'.format(output, output.size()))\n",
    "        #print('in Decoder, the initial hidden is {}, dimension is {}'.format(hidden, hidden.size()))\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        #print('in Decoder, output of GRU is {}, dimension is {}'.format(output, output.size()))\n",
    "        #print('in Decoder, hidden of GRU is {}, dimension is {}'.format(hidden, hidden.size()))\n",
    "        \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        #print('in Decoder, output after softmax is {}, dimension is {}'.format(output, output.size()))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        initHidden = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "        #print('in Decoder, initHidden is {}, dimension is {} \\n'.format(initHidden, initHidden.size()))\n",
    "        return initHidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to mask loss after EOS\n",
    "def mask_ind(arr):\n",
    "    arr = arr.cpu().numpy()\n",
    "    batch_size = arr.shape[1]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        if 1 in arr[:,i]:\n",
    "            ind = np.where(arr[:,i]== 1)[0][0]\n",
    "        \n",
    "            arr[:,i][:ind+1]=1\n",
    "            arr[:,i][ind+1:]=0\n",
    "        else:\n",
    "            arr[:,i]=1  \n",
    "    return arr, np.count_nonzero(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTK1S9_xP5mH"
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer):\n",
    "    \n",
    "    batch_size = input_tensor.size()[1]\n",
    "    #print('in train, batch size is {}'.format(batch_size))\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    #print('in train, initial encoder hidden is {}, dimension is {}'.format(encoder_hidden, encoder_hidden.size()))\n",
    "    \n",
    "    encoder_optimizer.zero_grad()  \n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size()[0]\n",
    "    #print('in train, input_length is {}'.format(input_length))\n",
    "    target_length = target_tensor.size()[0]\n",
    "    #print('in train, target_length is {}'.format(target_length))\n",
    "   \n",
    "    _, context = encoder(input_tensor, encoder_hidden)\n",
    "    #print('in train encoder_hidden[0] is {}, dimension is {}'.format(encoder_hidden[0],encoder_hidden[0].size()))\n",
    "    #print('in train after concatenating encoder_hidden[0] and [1] is {}, dimension is {}'.format(torch.cat((encoder_hidden[0].cpu().data,encoder_hidden[1].cpu().data),dim = 1), torch.cat((encoder_hidden[0].cpu().data,encoder_hidden[1].cpu().data),dim = 1).size()))\n",
    "   \n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]*batch_size], device=device)  # decoder_input: torch.Size([1, 32])\n",
    "    decoder_hidden = context.to(device)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    #print('target_tensor is {}, dimension is {}'.format(target_tensor, target_tensor.size()))\n",
    "    \n",
    "    \n",
    "    #print('target_tensor is {}, dimension is {}'.format(target_tensor, target_tensor.size()))\n",
    "    #print('sentence 3 in this batch is {}, dimension is {}'.format(convert_idx_2_sent_new(target_tensor[:,2], target_tra)))\n",
    "    #print('sentence 3 in this batch is {}'.format(convert_idx_2_sent_new(target_tensor[:,2], target_tra)))\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        loss = 0 \n",
    "        criterion = nn.NLLLoss(reduce = True, ignore_index = 2, reduction='elementwise_mean') \n",
    "\n",
    "        for di in range(target_length):\n",
    "            #print('in teacher_forcing, step {}'.format(di))\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            decoder_input = target_tensor[di]  \n",
    "            #print('in teacher forcing, decoder_output at current timestep is {}, dimension is {}'.format(decoder_output, decoder_output.size()))\n",
    "            #print('predicted target at current timestep is {}, dimension is {}'.format(torch.argmax(decoder_output, dim=1), torch.argmax(decoder_output, dim=1).size()))\n",
    "            #print('true target at current timestep is {}, dimension is {}'.format(target_tensor[i], target_tensor[i].size()))\n",
    "            #print('predicted target at current timestep is {}, dimension is {}'.format(decoder_output, decoder_output.size()))\n",
    "            \n",
    "            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "            #print ('in teacher forcing, temp loss at current step is {}'.format(temp_loss))\n",
    "            #print('temp_loss for current batch, current token is {}, dimension is {}'.format(temp_loss, temp_loss.size()))\n",
    "            \n",
    "            loss += temp_loss\n",
    "            #loss += temp_loss * mask[di:di+1].float()  \n",
    "            #print('loss is {}, dimension is {}'.format(loss, loss.size()))\n",
    "            #ave_loss = loss.sum()/batch_size\n",
    "        ave_loss = loss/target_length\n",
    "            \n",
    "    else:\n",
    "        loss = None \n",
    "        criterion = nn.NLLLoss(reduction='none') \n",
    "        prediction = None\n",
    "\n",
    "        for di in range(target_length):\n",
    "            #print('in non_teacher forcing, step {}'.format(di))\n",
    "            \n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            #print('in non_teacher forcing, topi is {}, dimension is {}'.format(topi, topi.size()))\n",
    "            \n",
    "            if prediction is None:\n",
    "                prediction = topi.view(1,-1)\n",
    "            else:\n",
    "                prediction = torch.cat((prediction, topi.view(1,-1)), dim=0)\n",
    "            \n",
    "            #print('at current step, cumulative prediction is {}, dimension is {}'.format(prediction, prediction.size()))\n",
    "            \n",
    "                            \n",
    "            decoder_input = topi.transpose(0,1).detach()  # detach from history as input\n",
    "            #print('in non_teacher forcing, input of the current step is {}, dimension is {}'.format(topi.transpose(0,1),topi.transpose(0,1).size()))\n",
    "            #print('in non_teacher forcing decoder_output at current timestep is {}, dimension is {}'.format(decoder_output, decoder_output.size()))\n",
    "            \n",
    "            #print('predicted target at current timestep is {}, dimension is {}'.format(torch.argmax(decoder_output, dim=1), torch.argmax(decoder_output, dim=1).size()))\n",
    "\n",
    "            #print('true target at current timestep is {}, dimension is {}'.format(target_tensor[i], target_tensor[i].size()))\n",
    "            \n",
    "            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "            if loss is None:\n",
    "                loss = temp_loss.view(1,-1)\n",
    "            else:\n",
    "                loss = torch.cat((loss, temp_loss.view(1,-1)),dim=0)\n",
    "            #print('temp_loss for current batch, current token is {}, dimension is {}'.format(temp_loss, temp_loss.size()))\n",
    "    \n",
    "    #print('Final prediction is {}'.format(prediction))\n",
    "        mask, count = mask_ind(prediction)\n",
    "        total_loss = torch.sum(loss * torch.from_numpy(mask).float().to(device))\n",
    "        ave_loss = total_loss/count\n",
    "    #print('total_loss is {}, dimension is{}'.format(total_loss, total_loss.size()))        \n",
    "    ave_loss.backward()\n",
    "    encoder_optimizer.step()   \n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    #print('total valid predicted token is {}'.format(count))\n",
    "    #print('ave_loss type is {}'.format(type(ave_loss)))\n",
    "    #print('ave_loss.item() type is {}'.format(type(ave_loss.item())))\n",
    "    \n",
    "    return ave_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_idx_2_sent_new(idx_tensor, lang_obj):\n",
    "    word_list = []\n",
    "    for i in idx_tensor:\n",
    "        if i.item() not in set([PAD_IDX,EOS_token,SOS_token]):\n",
    "            word_list.append(lang_obj.index2word[i.item()])\n",
    "    sent = (' ').join(word_list)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_new(corpus,truths):\n",
    "    n = len(corpus)\n",
    "    pred_ls = []\n",
    "    true_ls = []\n",
    "    for i in range(n):\n",
    "        pred, true = corpus[i], truths[i]\n",
    "        pred_ls.append( [convert_idx_2_sent_new(sent, target_tra) for sent in pred])\n",
    "        true_ls.append([convert_idx_2_sent_new(sent, target_tra) for sent in true])\n",
    "    flattened_pred  = [val for sublist in pred_ls for val in sublist]\n",
    "    flattened_true  = [val for sublist in true_ls for val in sublist]\n",
    "    bleu= corpus_bleu(flattened_pred, [flattened_true]).score\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIbK23CaP5mO"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, data_loader, max_length=MAX_SENT_LEN):\n",
    "    start = time.time()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    inputs = []\n",
    "    corpus = []\n",
    "    truths = []\n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(data_loader):\n",
    "        inputs.append(input_sentences.to(device))#put into inputs: batch*seq: each row is a sentence\n",
    "        input_tensor = input_sentences.transpose(0,1).to(device)\n",
    "        truths.append(target_sentences.to(device))#put into truths: batch*seq: each row is a sentence\n",
    "        target_tensor = target_sentences.transpose(0,1).to(device) \n",
    "        input_length = input_tensor.size()[0]\n",
    "        batch_size = input_tensor.size()[1]\n",
    "    \n",
    "        \n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "       \n",
    "        _, context = encoder(input_tensor, encoder_hidden)\n",
    "       \n",
    "        decoder_hidden = context.to(device)\n",
    "        decoder_input = torch.tensor([[SOS_token]*batch_size], device=device) \n",
    "        decoded_words = torch.zeros(batch_size, max_length)\n",
    "    \n",
    "    \n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            decoded_words[:,di] = topi.squeeze()  #put into decoded_words: batch*seq\n",
    "            decoder_input = topi.transpose(0,1).detach()\n",
    "            #print('true target is {}, dimension is {}'.format(target_tensor[:,di],target_tensor[di].size()))\n",
    "            #print('before transpose, topi is {}, dimension is {}'.format(topi, topi.size()))\n",
    "            #print('after transpose, topi is {}, dimension is {}'.format(topi.transpose(0,1),topi.transpose(0,1).size()))\n",
    "        corpus.append(decoded_words)\n",
    "        \n",
    "        #print('last: decoded_words is {}, dimension is {}'.format(decoded_words, decoded_words.size()))\n",
    "        #print('last: inputs is {}, dimension is {}'.format(inputs, len(inputs)))\n",
    "        #print('last: truths is {}, dimension is {}'.format(truths, len(truths)))\n",
    "        #print(inputs[0].size(), corpus[0].size(), truths[0].size())\n",
    "    return inputs, corpus, truths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {\n",
    "    'HIDDEN_SIZE': 512,\n",
    "    'LR': 0.0004,\n",
    "    'EVA_EVERY': 200,\n",
    "    'DROP_OUT': 0.3,\n",
    "    'TEACHER_RATIO': 0.9,\n",
    "    'N_LAYERS': 1,\n",
    "    'KER_SIZE': 3,\n",
    "    'NUM_EPOCHS': 20   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4uAf72kP5mx",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1m 2s (- -2m 57s), Epoch: [1/20], Step: [200/3327], Train Loss: 6.2429876494407655, BLEU: 2.6154890736512644\n",
      "\n",
      "Input1:> 他 出身 阿富汗 <unk> <unk> 地区 有着 与 他人 不同 的 见解 他 坚持 让 他 的 女儿 我 的 母亲 去 上学 并 因此 被迫 与 他 的 父亲 断绝 父子 <unk> <unk> 关系\n",
      "\n",
      "Target1:= A total maverick from a remote province of Afghanistan , he insisted that his daughter , my mom , go to school , and for that he was <unk> by his father <unk> \n",
      "Predict1:< And the the of the of the , and the , and the , and the , and the world , and the world , and the world , and the world , and the <unk> <unk>\n",
      "\n",
      "Input2:> 我 本 以为 只有 我们 意大利 <unk> 大利 <unk> 在 非洲 栽 了 <unk> 但 当 我 知道 美国 国人 的 情况 英国 <unk> 国人 的 情况 法国 <unk> 国人 的 情况 当 看 了 他们 的 所作\n",
      "\n",
      "Target2:= I thought it was only us Italians <unk> around Africa , but then I saw what the Americans were doing , what the English were doing , what the French were doing , and after seeing what they \n",
      "Predict2:< And I , the , and , and , and , and , and the , and , and the , and , and the , and the , and the world , and the world , and\n",
      "Time: 2m 5s (- -3m 54s), Epoch: [1/20], Step: [400/3327], Train Loss: 5.569412119388581, BLEU: 3.0343154782049306\n",
      "new best achieved\n",
      "\n",
      "Input1:> 他 出身 阿富汗 <unk> <unk> 地区 有着 与 他人 不同 的 见解 他 坚持 让 他 的 女儿 我 的 母亲 去 上学 并 因此 被迫 与 他 的 父亲 断绝 父子 <unk> <unk> 关系\n",
      "\n",
      "Target1:= A total maverick from a remote province of Afghanistan , he insisted that his daughter , my mom , go to school , and for that he was <unk> by his father <unk> \n",
      "Predict1:< And the , the , the , , the , , the , , the , , and the of the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "Input2:> 我 本 以为 只有 我们 意大利 <unk> 大利 <unk> 在 非洲 栽 了 <unk> 但 当 我 知道 美国 国人 的 情况 英国 <unk> 国人 的 情况 法国 <unk> 国人 的 情况 当 看 了 他们 的 所作\n",
      "\n",
      "Target2:= I thought it was only us Italians <unk> around Africa , but then I saw what the Americans were doing , what the English were doing , what the French were doing , and after seeing what they \n",
      "Predict2:< And I was a lot of the , and I was a lot of the , and the of the , and the of the world , and the of the <unk> <unk>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c47c9a6f0929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         loss = train(input_tensor, target_tensor, encoder1,\n\u001b[0;32m---> 39\u001b[0;31m                      decoder1, encoder_optimizer, decoder_optimizer)\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-8756fc0c60c6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mave_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m#print('total_loss is {}, dimension is{}'.format(total_loss, total_loss.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mave_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = hyper['HIDDEN_SIZE']\n",
    "learning_rate = hyper['LR']\n",
    "dropout_p = hyper['DROP_OUT']\n",
    "teacher_forcing_ratio = hyper['TEACHER_RATIO']\n",
    "n_layers = hyper['N_LAYERS']\n",
    "ker_size = hyper['KER_SIZE']\n",
    "num_epoch = hyper['NUM_EPOCHS']\n",
    "eva_every = hyper['EVA_EVERY']\n",
    "early_stopping = True\n",
    "patience = 30\n",
    "required_progress = 0.0001\n",
    "best_score = None\n",
    "count = 0\n",
    "start_epoch=0\n",
    "filename = 'best'\n",
    "\n",
    "encoder1 = EncoderCNN(source_tra.n_words,hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, target_tra.n_words).to(device)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder1.parameters(), lr=learning_rate)\n",
    "# decoder_scheduler = ExponentialLR(decoder_optimizer, gamma=0.95)\n",
    "# encoder_scheduler = ExponentialLR(decoder_optimizer, gamma=0.95)\n",
    "\n",
    "whole_train_loss = []\n",
    "whole_val_bleu = []\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    print_bleu_score_val = []\n",
    "    print_losses = []\n",
    "    print_loss_total = 0    \n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(train_loader): \n",
    "        encoder1.train()\n",
    "        decoder1.train()\n",
    "        input_tensor = input_sentences.transpose(0,1)   \n",
    "        target_tensor = target_sentences.transpose(0,1)\n",
    "        loss = train(input_tensor, target_tensor, encoder1,\n",
    "                     decoder1, encoder_optimizer, decoder_optimizer)\n",
    "        print_loss_total += loss\n",
    "        \n",
    "        if i > 0 and i % eva_every == 0:\n",
    "            inputs, corpus, truths = evaluate(encoder1, decoder1, val_loader, max_length=MAX_SENT_LEN)\n",
    "            bleu_score_val_avg = bleu_new(corpus, truths)\n",
    "\n",
    "            print_loss_avg = print_loss_total / eva_every\n",
    "            print_loss_total = 0\n",
    "            print('Time: {}, Epoch: [{}/{}], Step: [{}/{}], Train Loss: {}, BLEU: {}'.format(\n",
    "                timeSince(start, i + 1/len(train_loader)), epoch, num_epoch, i, \n",
    "                len(train_loader),print_loss_avg,bleu_score_val_avg))\n",
    "            \n",
    "            print_bleu_score_val.append(bleu_score_val_avg)\n",
    "            if best_score is None:\n",
    "                  best_score = bleu_score_val_avg\n",
    "            if bleu_score_val_avg < best_score + required_progress:\n",
    "                  count += 1\n",
    "            elif bleu_score_val_avg > best_score:\n",
    "                state = {'epoch': start_epoch + epoch + 1, \n",
    "                           'state_dict_enc': encoder1.state_dict(),\n",
    "                           'state_dict_dec': decoder1.state_dict(), \n",
    "                           'best_accuracy': best_score, \n",
    "                           'optimizer_enc': encoder_optimizer.state_dict(),\n",
    "                          'optimizer_dec': decoder_optimizer.state_dict()}\n",
    "                print ('new best achieved')\n",
    "                torch.save(state, filename+'.pth.tar')\n",
    "                best_score = bleu_score_val_avg\n",
    "                count = 0\n",
    "            if early_stopping:\n",
    "                if count >= patience:\n",
    "                    print(\"earily stop triggered\")\n",
    "\n",
    "\n",
    "            print('\\nInput1:> %s'%(' '.join([source_tra.index2word[i.item()] for i in inputs[0][3] if i.item() not in set([PAD_IDX,EOS_token,SOS_token])])))\n",
    "            print('\\nTarget1:= %s'%(convert_idx_2_sent_new(truths[0][3], target_tra)),\n",
    "                    '\\nPredict1:< %s' %(convert_idx_2_sent_new(corpus[0][3], target_tra)))\n",
    "            \n",
    "            print('\\nInput2:> %s'%(' '.join([source_tra.index2word[i.item()] for i in inputs[1][3] if i.item() not in set([PAD_IDX,EOS_token,SOS_token])])))\n",
    "            print('\\nTarget2:= %s'%(convert_idx_2_sent_new(truths[1][3], target_tra)),\n",
    "                    '\\nPredict2:< %s' %(convert_idx_2_sent_new(corpus[1][3], target_tra)))\n",
    "    if early_stopping:\n",
    "        if count >= patience:\n",
    "            break\n",
    "\n",
    "    whole_train_loss.append(print_loss_avg)\n",
    "    whole_val_bleu.append(print_bleu_score_val)\n",
    "    pkl.dump(whole_val_bleu, open(data_dir+'NOATTNCNN_bleu_score_list.pkl','wb'))\n",
    "    pkl.dump(whole_train_loss,open(data_dir+'NOATTNCNN_train_loss.pkl','wb'))\n",
    "    pkl.dump(truths, open(data_dir+'NOATTNCNN_truths.pkl','wb'))\n",
    "    pkl.dump(corpus,open(data_dir+'NOATTNCNN_corpus.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_NOATTN_V3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
