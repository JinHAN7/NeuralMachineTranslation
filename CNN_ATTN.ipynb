{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pickle as pkl\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import sacrebleu\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import time\n",
    "import math\n",
    "import html\n",
    "from sacrebleu import corpus_bleu, raw_corpus_bleu\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/yh1844/data'\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_IDX = 2\n",
    "UNK_IDX = 3\n",
    "VOCAB_SIZE = 50000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_loader(file_name):\n",
    "    with open(file_name+'.p', 'rb') as f:\n",
    "        objct = pkl.load(f)\n",
    "    return(objct)\n",
    "\n",
    "def pkl_dumper(obj, file_name):\n",
    "    with open(file_name+'.p', 'wb') as f:\n",
    "        pkl.dump(obj, f, protocol=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_wordvec(lan):\n",
    "    if lan == 'zh':\n",
    "        filename = 'wiki.zh.vec'\n",
    "    elif lan == 'en':\n",
    "        filename = 'wiki-news-300d-1M.vec'\n",
    "    else:\n",
    "        filename = 'wiki.vi.vec' #Vietnamese\n",
    "    with open(os.path.join(data_dir, filename),encoding='utf-8') as f:\n",
    "        word_vecs = np.zeros((VOCAB_SIZE+4, 300))\n",
    "        word_vecs[UNK_IDX] = np.random.normal(scale=0.6, size=(300, ))\n",
    "        word_vecs[SOS_token] = np.random.normal(scale=0.6, size=(300, ))\n",
    "        word_vecs[EOS_token] = np.random.normal(scale=0.6, size=(300, ))\n",
    "\n",
    "        words_ft = {'<pad>': PAD_IDX,\n",
    "                   '<unk>': UNK_IDX, \n",
    "                   '<sos>': SOS_token,\n",
    "                   '<eos>': EOS_token}\n",
    "        idx2words_ft = {PAD_IDX:'<pad>', UNK_IDX: '<unk>', SOS_token: '<sos>', EOS_token: '<eos>'}\n",
    "        ordered_words_ft = ['<sos>', '<eos>', '<pad>', '<unk>']\n",
    "        count = 0\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            if len(idx2words_ft) >= VOCAB_SIZE: \n",
    "                break\n",
    "            s = line.split()\n",
    "            if (np.asarray(s[1:]).size != 300):\n",
    "                print(lan, i, np.asarray(s[1:]).size)\n",
    "                continue\n",
    "            word_vecs[count+4, :] = np.asarray(s[1:])\n",
    "            words_ft[s[0]] = count+4\n",
    "            idx2words_ft[count+4] = s[0]\n",
    "            ordered_words_ft.append(s[0])\n",
    "            count += 1\n",
    "    word_vecs = torch.FloatTensor(word_vecs)\n",
    "    pkl_dumper(word_vecs, os.path.join(data_dir, lan + '_word_vecs'))\n",
    "    pkl_dumper(words_ft, os.path.join(data_dir, lan + '_words_ft'))\n",
    "    pkl_dumper(idx2words_ft, os.path.join(data_dir, lan + '_idx2words_ft'))\n",
    "    pkl_dumper(ordered_words_ft, os.path.join(data_dir, lan + '_ordered_words_ft'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_pretrained_wordvec('zh')\n",
    "# load_pretrained_wordvec('en')\n",
    "# load_pretrained_wordvec('vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained vectors\n",
    "word_vecs = {}\n",
    "word2index = {}\n",
    "index2word = {}\n",
    "\n",
    "word_vecs['en'] = pkl_loader(data_dir+'/en_word_vecs')\n",
    "word_vecs['zh'] = pkl_loader(data_dir+'/zh_word_vecs')\n",
    "word_vecs['vi'] = pkl_loader(data_dir+'/vi_word_vecs')\n",
    "target_pre_trained_emb = word_vecs['en']\n",
    "word2index['en'] = pkl_loader(data_dir+'/en_words_ft')\n",
    "word2index['zh'] = pkl_loader(data_dir+'/zh_words_ft')\n",
    "word2index['vi'] = pkl_loader(data_dir+'/vi_words_ft')\n",
    "index2word['en'] = pkl_loader(data_dir+'/en_idx2words_ft')\n",
    "index2word['zh'] = pkl_loader(data_dir+'/zh_idx2words_ft')\n",
    "index2word['vi'] = pkl_loader(data_dir+'/vi_idx2words_ft')\n",
    "\n",
    "VOCAB_SIZE = len(word2index['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name, index2word, word2index):\n",
    "        self.name = name\n",
    "        self.word2index = word2index\n",
    "        self.index2word = index2word\n",
    "        self.n_words = len(index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = html.unescape(s)\n",
    "    return s\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingLangs(sourcelang, targetlang, setname):\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    print('Reading lines...')\n",
    "    # Read the file \n",
    "    with open(data_dir+'/iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,sourcelang), encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            input_ls.append([normalizeString(word) for word in line.split()])\n",
    "    with open(data_dir+'/iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,targetlang), encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            output_ls.append([normalizeString(word) for word in line.split()])\n",
    "    pairs = list(zip(input_ls, output_ls))\n",
    "    pairs = [pair for pair in pairs if (len(pair[0])+len(pair[1]))>0]\n",
    "    print('Read %s sentence pairs'%(len(input_ls)))\n",
    "    if sourcelang == 'zh':\n",
    "        input_lang = Lang(sourcelang, index2word['zh'], word2index['zh'])\n",
    "    else:\n",
    "        input_lang = Lang(sourcelang, index2word['vi'], word2index['vi'])\n",
    "    output_lang = Lang(targetlang, index2word['en'], word2index['en'])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213377 sentence pairs\n",
      "Counted words:\n",
      "zh 50004\n",
      "en 50004\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Counted words:\n",
      "zh 50004\n",
      "en 50004\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Counted words:\n",
      "zh 50004\n",
      "en 50004\n"
     ]
    }
   ],
   "source": [
    "source_tra, target_tra, pairs_tra = loadingLangs('zh', 'en', 'train')\n",
    "source_val, target_val, pairs_val = loadingLangs('zh', 'en', 'dev')\n",
    "source_tes, target_tes, pairs_tes = loadingLangs('zh', 'en', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair,source,target):\n",
    "    input_lang = source\n",
    "    output_lang = target\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]).reshape((-1))\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1]).reshape((-1))\n",
    "    return (input_tensor, input_tensor.shape[0], target_tensor, target_tensor.shape[0])\n",
    "\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, source, target, pairs):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        inp_ten, inp_len, tar_ten, tar_len = tensorsFromPair(self.pairs[key], self.source, self.target)\n",
    "        item = {}\n",
    "        item['inputtensor'] = inp_ten[:MAX_SENT_LEN]\n",
    "        item['inputlen'] = min(inp_len, MAX_SENT_LEN)\n",
    "        item['targettensor'] = tar_ten[:MAX_SENT_LEN]\n",
    "        item['targetlen'] = min(tar_len, MAX_SENT_LEN)\n",
    "        return item\n",
    "\n",
    "train_data = NMTDataset(source_tra, target_tra, pairs_tra)\n",
    "val_data = NMTDataset(source_tra, target_tra, pairs_val)\n",
    "test_data = NMTDataset(source_tra, target_tra, pairs_tes)\n",
    "\n",
    "\n",
    "#collate function\n",
    "\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    src_data, tar_data, src_len, tar_len = [], [], [], []\n",
    "    \n",
    "    for datum in batch: \n",
    "        src_len.append(datum['inputlen'])\n",
    "        tar_len.append(datum['targetlen'])\n",
    "    \n",
    "    max_length = [np.max(src_len), np.max(tar_len)]\n",
    "    for datum in batch: \n",
    "        \n",
    "        src_datum = np.pad(np.array(datum['inputtensor']),\n",
    "                                pad_width=((0, max_length[0]-datum['inputlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        tar_datum = np.pad(np.array(datum['targettensor']),\n",
    "                                pad_width=((0, max_length[1]-datum['targetlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_datum)\n",
    "        tar_data.append(tar_datum)\n",
    "        \n",
    "        \n",
    "    ind_dec_order = np.argsort(src_len)[::-1]\n",
    "    src_data = np.array(src_data)[ind_dec_order]\n",
    "    src_len = np.array(src_len)[ind_dec_order]\n",
    "    tar_data = np.array(tar_data)[ind_dec_order]\n",
    "    tar_len = np.array(tar_len)[ind_dec_order]\n",
    "    return [torch.from_numpy(np.array(src_data)).to(device),torch.from_numpy(np.array(tar_data)).to(device),\n",
    "                torch.LongTensor(np.array(src_len)).to(device),torch.LongTensor(np.array(tar_len)).to(device)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=True, collate_fn=collate_func)\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=False, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {\n",
    "    'HIDDEN_SIZE': 512,\n",
    "    'LR': 0.0004,\n",
    "    'EVA_EVERY': 200,\n",
    "    'DROP_OUT': 0,\n",
    "    'TEACHER_RATIO': 0,\n",
    "    'N_LAYERS': 1,\n",
    "    'KER_SIZE': 3,\n",
    "    'NUM_EPOCHS': 20   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, pretrained=True, ker_size=3, dropout_p=0.1):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        if pretrained==True:\n",
    "            word_vec = word_vecs[source_tra.name]\n",
    "            self.embedding = nn.Embedding(input_size, emb_size, padding_idx=PAD_IDX)\n",
    "            self.embedding.weight = nn.Parameter(word_vec)\n",
    "            self.embedding.requires_grad = False\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(input_size, emb_size, padding_idx=PAD_IDX)\n",
    "          \n",
    "          \n",
    "        self.seq1 = nn.Sequential(nn.Conv1d(emb_size, hidden_size, kernel_size=ker_size, padding=(ker_size-1)//2),\n",
    "                                nn.ReLU())\n",
    "        self.seq2 = nn.Sequential(nn.Conv1d(hidden_size, hidden_size, kernel_size=ker_size, padding=(ker_size-1)//2),\n",
    "                                nn.ReLU())\n",
    "                                #nn.MaxPool1d(kernel_size=ker_size, stride=1, padding=(ker_size-1)//2))\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden=None): \n",
    "        seq_len, batch_size = input.size() # input size is torch.Size([38, 64])\n",
    "        # input size for conv1d is , N is a batch size, C denotes a number of channels, L is a length of signal sequence.\n",
    "        output = self.embedding(input) #\n",
    "#         print('output size is', output.size())\n",
    "        output = output.permute(1, 2, 0)  #\n",
    "#         print('output size is', output.size())\n",
    "        #.permute()view(batch_size, -1, seq_len)\n",
    "        output = self.seq1(output)\n",
    "#         print('output size is', output.size())\n",
    "        output = self.seq2(output)\n",
    "        hidden = torch.sum(output, dim=2)\n",
    "\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "\n",
    "\n",
    "        output = output.permute(2, 0, 1)\n",
    "        hidden = self.fc(hidden)\n",
    "        hidden = F.relu(self.dropout(hidden))\n",
    "        hidden = self.fc(hidden)\n",
    "\n",
    "\n",
    "        return output, hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Some code was inspired by Bahdanau's work.(Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 'Neural machine translation by jointly learning to align and translate.' arXiv preprint arXiv:1409.0473 (2014).\"\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.normal_(mean=0, std=stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        max_len = encoder_outputs.size(0)\n",
    "        Hid_copy = hidden.repeat(max_len,1,1).transpose(0,1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0,1) \n",
    "        attn_energies = self.score(Hid_copy,encoder_outputs) \n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) \n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        score = F.tanh(self.attn(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        score = score.transpose(2,1) \n",
    "        v = self.v.repeat(encoder_outputs.data.shape[0],1).unsqueeze(1) \n",
    "        score = torch.bmm(v,score) \n",
    "        return score.squeeze(1) \n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hid_size, emb_size, out_size, pretra = False,n_layers=1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "       \n",
    "        self.n_layers = n_layers\n",
    "        self.hid_size = hid_size\n",
    "        self.emb_size = emb_size\n",
    "        self.out_size = out_size\n",
    "          \n",
    "        if pretra:\n",
    "            emb_mat = torch.from_numpy(target_pre_trained_emb.numpy()).float()\n",
    "            self.embedding = nn.Embedding.from_pretrained(emb_mat,freeze = True)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(out_size, emb_size)\n",
    "       \n",
    "        self.attn = Attn('concat', hid_size)\n",
    "        self.gru = nn.GRU(hid_size + emb_size, hidden_size, n_layers, dropout=0.1)\n",
    "      \n",
    "        self.out = nn.Linear(hid_size, out_size)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        \n",
    "        \n",
    "#         print('dec, word input', word_input.size())\n",
    "        word_embedded = self.embedding(word_input.squeeze()).view(1, -1, self.emb_size) \n",
    "       \n",
    "#         print('dec, wembd', word_embedded.size())\n",
    "        \n",
    "#         print('dec, last hidden', last_hidden.size())\n",
    "#         print('dec, enc outp', encoder_outputs.size())\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  \n",
    "        context = context.transpose(0, 1) \n",
    "#         print('dec, context', context.size())\n",
    "#         print('dec, wembd', word_embedded.size())\n",
    "        \n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "#         print('dec rnn input', rnn_input.size())\n",
    "#         print('dec last hidden', last_hidden.size())\n",
    "        \n",
    "        output, hidden = self.gru(rnn_input, last_hidden[-1].unsqueeze(0))\n",
    "        output = output.squeeze(0)  \n",
    "        \n",
    "        output = F.log_softmax(self.out(output))\n",
    "        \n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, input_len, target_len, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_SENT_LEN):\n",
    "    \n",
    "    hidden_size = hyper['HIDDEN_SIZE']\n",
    "    learning_rate = hyper['LR']\n",
    "    dropout_p = hyper['DROP_OUT']\n",
    "    teacher_forcing_ratio = hyper['TEACHER_RATIO']\n",
    "    n_layers = hyper['N_LAYERS']\n",
    "    ker_size = hyper['KER_SIZE']\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    scheduler_encoder = ExponentialLR(encoder_optimizer, 0.95) \n",
    "    scheduler_decoder = ExponentialLR(decoder_optimizer, 0.95) \n",
    "\n",
    "    max_input_len = max(input_len)\n",
    "    max_target_len = max(target_len)\n",
    "    \n",
    "    batch_size = input_tensor.size()[1]\n",
    "    \n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # feed-forward layer resulting encoder outputs, ei refers to each word token in input sentence\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "    decoder_input = torch.tensor([[SOS_token]*batch_size], device=device) \n",
    "    \n",
    "    decoder_hidden = encoder_hidden#torch.cat([encoder_hidden[0, :, :].unsqueeze(0), encoder_hidden[1, :, :].unsqueeze(0)], dim = 0)\n",
    "\n",
    "     \n",
    "    #print('input to decoder:', decoder_input.size(), decoder_hidden.size(), encoder_outputs.size())\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing: \n",
    "        for di in range(max_target_len):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            decoder_input = target_tensor[di].view(batch_size,1)  \n",
    "            loss += criterion(decoder_output, target_tensor[di])    \n",
    "    else:\n",
    "  \n",
    "        for di in range(max_target_len):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(1)\n",
    "    \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), 3)\n",
    "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), 3)\n",
    "    encoder_optimizer.step() \n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / float(max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_new(corpus,truths):\n",
    "    n = len(corpus)\n",
    "    pred_ls = []\n",
    "    true_ls = []\n",
    "    for i in range(n):\n",
    "        pred, true = corpus[i], truths[i]\n",
    "        pred_ls.append( [convert_idx_2_sent_new(sent, target_tra) for sent in pred])\n",
    "        true_ls.append([convert_idx_2_sent_new(sent, target_tra) for sent in true])\n",
    "    flattened_pred  = [val for sublist in pred_ls for val in sublist]\n",
    "    flattened_true  = [val for sublist in true_ls for val in sublist]\n",
    "    bleu= corpus_bleu(flattened_pred, [flattened_true]).score\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_idx_2_sent_new(idx_tensor, lang_obj):\n",
    "    word_list = []\n",
    "\n",
    "    for i in idx_tensor:\n",
    "        if i.item() not in set([PAD_IDX,EOS_token,SOS_token]):\n",
    "            word_list.append(lang_obj.index2word[i.item()])\n",
    "\n",
    "    sent = (' ').join(word_list)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, data_loader, mode_enc, mode_dec, max_length=MAX_SENT_LEN):\n",
    "    start = time.time()\n",
    "    hidden_size = hyper['HIDDEN_SIZE']\n",
    "    learning_rate = hyper['LR']\n",
    "    dropout_p = hyper['DROP_OUT']\n",
    "    teacher_forcing_ratio = hyper['TEACHER_RATIO']\n",
    "    n_layers = hyper['N_LAYERS']\n",
    "    ker_size = hyper['KER_SIZE']\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    inputs = []\n",
    "    corpus = []\n",
    "    truths = []\n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(data_loader):\n",
    "        \n",
    "        input_tensor = input_sentences.transpose(0,1).to(device) #L*B\n",
    "        target_tensor = target_sentences.transpose(0,1).to(device)\n",
    "    \n",
    "        inputs.append(input_sentences)\n",
    "        truths.append(target_sentences)\n",
    "        \n",
    "        max_input_len = max(len1)\n",
    "        max_target_len = max(len2)\n",
    "        \n",
    "        \n",
    "        batch_size = input_tensor.size()[1]\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, len1)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]*batch_size], device=device) \n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        decoded_words = torch.zeros(batch_size, int(max_input_len*1.5))\n",
    "    \n",
    "        for di in range(int(max_input_len*1.5)):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)        \n",
    "            topv, topi = decoder_output.topk(1) #topi B*1\n",
    "            decoded_words[:,di] = topi.squeeze()\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(1)\n",
    "            \n",
    "        corpus.append(decoded_words)\n",
    "#         print(inputs[0].size(), corpus[0].size(), truths[0].size()) # all B*L\n",
    "    return inputs, corpus, truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_beam(encoder, decoder, data_loader, mode_enc, mode_dec, max_length=MAX_SENT_LEN, beam=True, beam_width=3):\n",
    "    start = time.time()\n",
    "    hidden_size = hyper['HIDDEN_SIZE']\n",
    "    learning_rate = hyper['LR']\n",
    "    dropout_p = hyper['DROP_OUT']\n",
    "    teacher_forcing_ratio = hyper['TEACHER_RATIO']\n",
    "    n_layers = hyper['N_LAYERS']\n",
    "    ker_size = hyper['KER_SIZE']\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    inputs = []\n",
    "    corpus = []\n",
    "    truths = []\n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(data_loader):\n",
    "\n",
    "        input_tensor = input_sentences.transpose(0,1).to(device) #L*B\n",
    "        target_tensor = target_sentences.transpose(0,1).to(device)\n",
    "    \n",
    "        inputs.append(input_sentences)\n",
    "        truths.append(target_sentences)\n",
    "        \n",
    "        max_input_len = max(len1)\n",
    "        max_target_len = max(len2)\n",
    "        \n",
    "        \n",
    "        batch_size = input_tensor.size()[1]\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, len1)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]*batch_size], device=device) \n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        max_length = int(max_input_len*1.5)\n",
    "        decoded_words = torch.zeros(batch_size, max_length)\n",
    "        if beam == False:\n",
    "            \n",
    "            for di in range(int(max_input_len*1.5)):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)        \n",
    "                topv, topi = decoder_output.topk(1) #topi B*1\n",
    "                decoded_words[:,di] = topi.squeeze()\n",
    "                decoder_input = topi.squeeze().detach().unsqueeze(1)\n",
    "\n",
    "            corpus.append(decoded_words)\n",
    "    \n",
    "            for di in range(max_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)        \n",
    "                topv, topi = decoder_output.topk(1) #topi B*1\n",
    "                decoded_words[:, di] = topi.squeeze()\n",
    "                #print('topi is {}, size is {}'.format(topi, topi.size()))\n",
    "                decoder_input = topi.detach()\n",
    "\n",
    "            corpus.append(decoded_words)\n",
    "#         print(inputs[0].size(), corpus[0].size(), truths[0].size()) # all B*L\n",
    "        else:\n",
    "            completed_sents = []\n",
    "            caches = [[] for i in range(max_length)]\n",
    "            caches[0] = [([SOS_token],0, encoder_hidden)]\n",
    "            for di in range(1,max_length):\n",
    "                for (prev_tokens, log_prob, decoder_hidden) in caches[di-1]:\n",
    "                    decoder_input = torch.tensor(prev_tokens[-1], device=device) \n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                    topv, topi = decoder_output.topk(beam_width)\n",
    "                    log_prob_cur = [prob for prob in topv.squeeze().detach()]\n",
    "                    idxs_cur = [ind.item() for ind in topi.squeeze().detach()]\n",
    "                    for i in range(beam_width):\n",
    "                        caches[di].append((prev_tokens+[idxs_cur[i]], log_prob_cur[i]+log_prob, decoder_hidden))\n",
    "                        if idxs_cur[i]==EOS_token:\n",
    "                            completed_sents.append((prev_tokens+[idxs_cur[i]], log_prob_cur[i]+log_prob))\n",
    "                    caches[di].sort(key=lambda x: x[1], reverse=True)\n",
    "                    caches[di] = caches[di][:beam_width]\n",
    "            caches[max_length-1].sort(key=lambda x: x[1], reverse=True)\n",
    "            for i in range(beam_width):\n",
    "                completed_sents.append((caches[max_length-1][i][0], caches[max_length-1][i][1]))\n",
    "            completed_sents.sort(key=lambda x: x[1]/(len(x[0])**0.6), reverse=True)\n",
    "            decoded_words = torch.tensor(completed_sents[0][0]).to(device)\n",
    "            \n",
    "            corpus.append(decoded_words.unsqueeze(0))\n",
    "        \n",
    "    return inputs, corpus, truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yh1844/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Time: 1m 19s (- -2m 41s), Epoch: [1/20], Step: [200/3332], Train Loss: 3.7572551938107126, BLEU score: 2.796375772080839\n",
      "\n",
      "Input> 他 出身 阿富汗 <unk> <unk> 地区 有着 与 他人 不同 的 见解 他 坚持 让 他 的 女儿 我 的 母亲 去 上学 并 因此 被迫 与 他 的 父亲 断绝 父子 <unk> <unk> 关系\n",
      "\n",
      "Target= A total maverick from a remote province of Afghanistan , he insisted that his daughter , my mom , go to school , and for that he was <unk> by his father <unk> \n",
      "Predict< So , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "\n",
      "Input2> 对 我 来说 阿富汗 充满 了 希望 和 无限 的 可能 可能性 每 一天 在 <unk> 读书 的 女孩 <unk> <unk> 都 这么 提醒 着 我\n",
      "\n",
      "Target2= To me , Afghanistan is a country of hope and boundless possibilities , and every single day the girls of <unk> remind me of that <unk> \n",
      "Predict2< So , , , , , , , , , , , , , , , , , , ,\n",
      "new best achieved\n",
      "-----------------------------------------\n",
      "Time: 2m 39s (- -3m 21s), Epoch: [1/20], Step: [400/3332], Train Loss: 3.3756724618610594, BLEU score: 3.9549592413894037\n",
      "\n",
      "Input> 他 出身 阿富汗 <unk> <unk> 地区 有着 与 他人 不同 的 见解 他 坚持 让 他 的 女儿 我 的 母亲 去 上学 并 因此 被迫 与 他 的 父亲 断绝 父子 <unk> <unk> 关系\n",
      "\n",
      "Target= A total maverick from a remote province of Afghanistan , he insisted that his daughter , my mom , go to school , and for that he was <unk> by his father <unk> \n",
      "Predict< And , the , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "\n",
      "Input2> 对 我 来说 阿富汗 充满 了 希望 和 无限 的 可能 可能性 每 一天 在 <unk> 读书 的 女孩 <unk> <unk> 都 这么 提醒 着 我\n",
      "\n",
      "Target2= To me , Afghanistan is a country of hope and boundless possibilities , and every single day the girls of <unk> remind me of that <unk> \n",
      "Predict2< And , the , , , , , , , , , , , , , , , , , , , , ,\n",
      "-----------------------------------------\n",
      "Time: 3m 57s (- -4m 3s), Epoch: [1/20], Step: [600/3332], Train Loss: 3.310429176531338, BLEU score: 2.119388796825413\n",
      "\n",
      "Input> 他 出身 阿富汗 <unk> <unk> 地区 有着 与 他人 不同 的 见解 他 坚持 让 他 的 女儿 我 的 母亲 去 上学 并 因此 被迫 与 他 的 父亲 断绝 父子 <unk> <unk> 关系\n",
      "\n",
      "Target= A total maverick from a remote province of Afghanistan , he insisted that his daughter , my mom , go to school , and for that he was <unk> by his father <unk> \n",
      "Predict< And , the , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "\n",
      "Input2> 对 我 来说 阿富汗 充满 了 希望 和 无限 的 可能 可能性 每 一天 在 <unk> 读书 的 女孩 <unk> <unk> 都 这么 提醒 着 我\n",
      "\n",
      "Target2= To me , Afghanistan is a country of hope and boundless possibilities , and every single day the girls of <unk> remind me of that <unk> \n",
      "Predict2< And , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "new best achieved\n",
      "-----------------------------------------\n",
      "Time: 5m 17s (- -6m 42s), Epoch: [1/20], Step: [800/3332], Train Loss: 3.3169966115449587, BLEU score: 4.965049936768266\n",
      "\n",
      "Input> 他 出身 阿富汗 <unk> <unk> 地区 有着 与 他人 不同 的 见解 他 坚持 让 他 的 女儿 我 的 母亲 去 上学 并 因此 被迫 与 他 的 父亲 断绝 父子 <unk> <unk> 关系\n",
      "\n",
      "Target= A total maverick from a remote province of Afghanistan , he insisted that his daughter , my mom , go to school , and for that he was <unk> by his father <unk> \n",
      "Predict< And , , , , , , , , , , , , , , , , , , , , , ,\n",
      "\n",
      "Input2> 对 我 来说 阿富汗 充满 了 希望 和 无限 的 可能 可能性 每 一天 在 <unk> 读书 的 女孩 <unk> <unk> 都 这么 提醒 着 我\n",
      "\n",
      "Target2= To me , Afghanistan is a country of hope and boundless possibilities , and every single day the girls of <unk> remind me of that <unk> \n",
      "Predict2< And I , , , , , , , , , , , , , , , <unk> <unk>\n",
      "-----------------------------------------\n",
      "Time: 6m 35s (- -7m 24s), Epoch: [1/20], Step: [1000/3332], Train Loss: 3.270776556918495, BLEU score: 3.6148800241970416\n",
      "\n",
      "Input> 他 出身 阿富汗 <unk> <unk> 地区 有着 与 他人 不同 的 见解 他 坚持 让 他 的 女儿 我 的 母亲 去 上学 并 因此 被迫 与 他 的 父亲 断绝 父子 <unk> <unk> 关系\n",
      "\n",
      "Target= A total maverick from a remote province of Afghanistan , he insisted that his daughter , my mom , go to school , and for that he was <unk> by his father <unk> \n",
      "Predict< And , , , , , , , , , , , , , , , , , , , , ,\n",
      "\n",
      "Input2> 对 我 来说 阿富汗 充满 了 希望 和 无限 的 可能 可能性 每 一天 在 <unk> 读书 的 女孩 <unk> <unk> 都 这么 提醒 着 我\n",
      "\n",
      "Target2= To me , Afghanistan is a country of hope and boundless possibilities , and every single day the girls of <unk> remind me of that <unk> \n",
      "Predict2< And , , , , , , , , , , , , , , , , , ,\n",
      "-----------------------------------------\n",
      "Time: 7m 53s (- -8m 6s), Epoch: [1/20], Step: [1200/3332], Train Loss: 3.236369723432602, BLEU score: 3.972065290262546\n",
      "\n",
      "Input> 他 出身 阿富汗 <unk> <unk> 地区 有着 与 他人 不同 的 见解 他 坚持 让 他 的 女儿 我 的 母亲 去 上学 并 因此 被迫 与 他 的 父亲 断绝 父子 <unk> <unk> 关系\n",
      "\n",
      "Target= A total maverick from a remote province of Afghanistan , he insisted that his daughter , my mom , go to school , and for that he was <unk> by his father <unk> \n",
      "Predict< And was I , , , , , , , , , , , , , , , , ,\n",
      "\n",
      "Input2> 对 我 来说 阿富汗 充满 了 希望 和 无限 的 可能 可能性 每 一天 在 <unk> 读书 的 女孩 <unk> <unk> 都 这么 提醒 着 我\n",
      "\n",
      "Target2= To me , Afghanistan is a country of hope and boundless possibilities , and every single day the girls of <unk> remind me of that <unk> \n",
      "Predict2< And I I , , , , , , , , , , , , , , ,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-9ec016b61038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         loss = train(input_tensor, target_tensor, len1, len2, encoder,\n\u001b[0;32m---> 41\u001b[0;31m                    decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-d36dda01580b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, input_len, target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hidden_size = hyper['HIDDEN_SIZE']\n",
    "learning_rate = hyper['LR']\n",
    "eva_every = hyper['EVA_EVERY']\n",
    "dropout_p = hyper['DROP_OUT']\n",
    "teacher_forcing_ratio = hyper['TEACHER_RATIO']\n",
    "n_layers = hyper['N_LAYERS']\n",
    "ker_size = hyper['KER_SIZE']\n",
    "num_epoch = hyper['NUM_EPOCHS']\n",
    "early_stopping = False\n",
    "patience = 3\n",
    "required_progress = 0.01\n",
    "\n",
    "encoder = EncoderCNN(source_tra.n_words, 300, hidden_size).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "\n",
    "decoder = AttnDecoderRNN(hidden_size, 300, target_tra.n_words, n_layers=1).to(device)\n",
    "\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss() \n",
    "plot_bleu_score_val = []\n",
    "plot_losses = []\n",
    "loss_total = 0 \n",
    "best_score = None\n",
    "count = 0\n",
    "filename = 'best_cnn' #########\n",
    "whole_val_bleu = []\n",
    "whole_train_loss = []\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    plot_bleu_score_val = []\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(train_loader): \n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        input_tensor = input_sentences.transpose(0,1).to(device)    \n",
    "        target_tensor = target_sentences.transpose(0,1).to(device)\n",
    "        loss = train(input_tensor, target_tensor, len1, len2, encoder,\n",
    "                   decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        loss_total += loss\n",
    "        \n",
    "        if i > 0 and i % eva_every == 0:\n",
    "            inputs, corpus, truths = evaluate(encoder, decoder, val_loader, max_length=MAX_SENT_LEN, mode_enc='rnn', mode_dec='noattn')\n",
    "\n",
    "            bleu_score_val_avg = bleu_new(corpus, truths)\n",
    "            loss_avg = loss_total / eva_every\n",
    "            loss_total = 0\n",
    "            plot_losses.append(loss_avg)\n",
    "            plot_bleu_score_val.append(bleu_score_val_avg)\n",
    "            if best_score is None:\n",
    "                best_score = bleu_score_val_avg\n",
    "            if bleu_score_val_avg < best_score + required_progress:\n",
    "                count += 1\n",
    "            elif bleu_score_val_avg > best_score:\n",
    "                state = {'epoch': epoch + 1, \n",
    "                           'state_dict_enc': encoder.state_dict(),\n",
    "                           'state_dict_dec': decoder.state_dict(), \n",
    "                           'best_accuracy': best_score, \n",
    "                           'optimizer_enc': encoder_optimizer.state_dict(),\n",
    "                          'optimizer_dec': decoder_optimizer.state_dict()}\n",
    "                print ('new best achieved')\n",
    "                torch.save(state, filename+'.pth')\n",
    "                pkl_dumper(inputs,os.path.join(data_dir,'attn_inputs_cnn'))\n",
    "                pkl_dumper(corpus,os.path.join(data_dir,'attn_pred_corpus_cnn'))\n",
    "                pkl_dumper(truths,os.path.join(data_dir, 'attn_target_truths_cnn')) \n",
    "                best_score = bleu_score_val_avg\n",
    "                count = 0\n",
    "                if early_stopping:\n",
    "                    if count >= patience:\n",
    "                        print(\"earily stop triggered\")\n",
    "                        break\n",
    "            print('-----------------------------------------')\n",
    "            print('Time: {0}, Epoch: [{1}/{2}], Step: [{3}/{4}], Train Loss: {5}, BLEU score: {6}'.format(\n",
    "                  timeSince(start, i + 1/len(train_loader)), epoch, num_epoch, i, \n",
    "                  len(train_loader), loss_avg, bleu_score_val_avg))\n",
    "            print('\\nInput> %s'%(' '.join([source_tra.index2word[i.item()] for i in inputs[0][3] if i.item() not in set([PAD_IDX,EOS_token,SOS_token])])))\n",
    "            print('\\nTarget= %s'%(convert_idx_2_sent_new(truths[0][3], target_tra)),\n",
    "              '\\nPredict< %s' %(convert_idx_2_sent_new(corpus[0][3], target_tra)))\n",
    "\n",
    "            print('\\nInput2> %s'%(' '.join([source_tra.index2word[i.item()] for i in inputs[0][13] if i.item() not in set([PAD_IDX,EOS_token,SOS_token])])))\n",
    "            print('\\nTarget2= %s'%(convert_idx_2_sent_new(truths[0][13], target_tra)),\n",
    "              '\\nPredict2< %s' %(convert_idx_2_sent_new(corpus[0][13], target_tra)))\n",
    "    if early_stopping:\n",
    "        if count >= patience:\n",
    "            print(\"earily stop triggered\")\n",
    "            break\n",
    "    whole_train_loss.append(plot_losses)\n",
    "    whole_val_bleu.append(plot_bleu_score_val)\n",
    "    print('-----------------------------------------')\n",
    "    pkl_dumper(whole_train_loss,os.path.join(data_dir,'attn_train_loss_cnn'))\n",
    "    pkl_dumper(whole_val_bleu,os.path.join(data_dir, 'attn_val_bleu_cnn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
